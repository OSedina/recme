{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from operator import itemgetter\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Добыча лайков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.instagram.com/p/Btndd-hhSF2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import Firefox\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "# настройки для запуска в фоновом режиме\n",
    "# opts = Options()\n",
    "# opts.set_headless()\n",
    "# assert opts.headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"patterns.json\", \"w\") as f:\n",
    "#     json.dump({\"liked_by_user\": class_pattern, \"liked_by_button\": 'zV_Nj'}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Это работает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"patterns.json\") as f:\n",
    "    patterns = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = Firefox()\n",
    "browser.get(url)\n",
    "browser.find_element_by_xpath(\"//a[@class='{}']\".format(patterns['liked_by_button'])).click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = browser.find_element_by_xpath(\"/html/body/div[3]/div/div[2]/div\")\n",
    "part_users = frame.text.split(\"\\n\")\n",
    "[part_users[i] for i in range(0, len(part_users), 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Скроллинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", frame)  # рабочий вариант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [i.text for i in browser.find_elements_by_xpath(\"//div[@class='{}']\".format(patterns[\"liked_by_user\"]))]\n",
    "SCROLL_PAUSE_TIME = 0.5\n",
    "\n",
    "# Get scroll height\n",
    "last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "while True:\n",
    "    # Scroll down to bottom\n",
    "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    data.extend([i.text for i in browser.find_elements_by_xpath(\"//div[@class='{}']\".format(patterns[\"liked_by_user\"]))])\n",
    "    # Wait to load page\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "    # Calculate new scroll height and compare with last scroll height\n",
    "    new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сбор данных постов, найденных по тэгу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Структура json\n",
    "```python\n",
    "[\"graphql\"][\"hashtag\"][\"edge_hashtag_to_media\"][\"page_info\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json(path, next_page=None):\n",
    "    \"\"\"\n",
    "    Returns json from url https://www.instagram.com/ + path\n",
    "    \n",
    "    path: str, part of url that follows https://www.instagram.com/\n",
    "    next_page: str, link to next page similar to linked list, \n",
    "    got from 'cursor' field in response json\n",
    "    \n",
    "    returns: dict\"\"\"\n",
    "    \n",
    "    url = \"https://www.instagram.com/\" + path\n",
    "    params = {\n",
    "        \"__a\": 1\n",
    "    }\n",
    "    if next_page:\n",
    "        params[\"max_id\"] = {next_page}\n",
    "        \n",
    "    r = requests.get(url, params=params)\n",
    "    try:\n",
    "        return r.json()\n",
    "    except json.decoder.JSONDecodeError as e:\n",
    "        print(r)\n",
    "        raise json.decoder.JSONDecodeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pages_by_tag(tag, max_pages, retries=5):\n",
    "    \"\"\"Instagram pages generator, yields n pages found by hash tag,\n",
    "    where n is less or equal than max_pages\n",
    "    \n",
    "    tag: str, instagram hash tag - a string without '#' symbol\n",
    "    max_pages: int, max n of pages to yield\n",
    "    \n",
    "    yields: dict\"\"\"\n",
    "    \n",
    "    next_page = None\n",
    "    page_n = 0\n",
    "    path = f\"explore/tags/{tag}/\"\n",
    "    retries_counter = 0\n",
    "    \n",
    "    while page_n <= max_pages:\n",
    "        page_n += 1\n",
    "        data = get_json(path, next_page)\n",
    "        print(f\"Got page {page_n}\")\n",
    "        \n",
    "        try:\n",
    "            page_info = data[\"graphql\"][\"hashtag\"][\"edge_hashtag_to_media\"][\"page_info\"]\n",
    "            retries_counter = 0\n",
    "        except KeyError:\n",
    "            if retries_counter <= retries:\n",
    "                time.sleep(1)\n",
    "                print(f\"Attempt #{retries_counter} on page {page_n}...\")\n",
    "                retries_counter += 1\n",
    "#             print(next_page)\n",
    "#             print(data)\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Unable to get page data\\ncursor: {next_page}\")\n",
    "                break\n",
    "        \n",
    "        if page_info[\"has_next_page\"]:\n",
    "            next_page = page_info[\"end_cursor\"]\n",
    "        else:\n",
    "            print(\"No more pages\")\n",
    "            break\n",
    "        \n",
    "        yield data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#использовать как декоратор\n",
    "def parse_page(page_json, keys, verbose=False):\n",
    "    \"\"\"Parses instagram page json\n",
    "    page_json: dict, json got from server response\n",
    "    keys: iterable, list of fields to retrieve from page_json\n",
    "    \n",
    "    returns: dict\"\"\"\n",
    "    \n",
    "    parsed_data = {}\n",
    "    page_posts = page_json[\"graphql\"][\"hashtag\"][\"edge_hashtag_to_media\"][\"edges\"]\n",
    "    for post in page_posts:\n",
    "#         print(1)\n",
    "        raw_post = post[\"node\"]\n",
    "        parsed_post = {}\n",
    "        for key in keys:\n",
    "            try:\n",
    "                parsed_post[key] = raw_post[key]\n",
    "            except KeyError:\n",
    "                try:\n",
    "                    parsed_post[key] = raw_post[\"edge_media_to_caption\"][\"edges\"][0][\"node\"][key]\n",
    "                except KeyError:\n",
    "                    if verbose:\n",
    "                        print(f\"Key {key} was not found\")\n",
    "                except IndexError as e:\n",
    "                    if verbose:\n",
    "                        print(f\"Key {key} was not found, reason:\\n{e}\")\n",
    "        parsed_data[raw_post[\"shortcode\"]] = parsed_post\n",
    "    return parsed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag_data(tag, keys, max_pages=10):\n",
    "    \"\"\"Collects data from instagram posts found by tag\n",
    "    \n",
    "    tag: str, instagram hash tag without '#' symbol\n",
    "    keys: fields from instagram response json to retrieve\n",
    "    max_pages: int, max n of pages to parse\n",
    "    \n",
    "    returns: dict, with pairs <post_shortcode>: {<post_data>}\"\"\"\n",
    "    \n",
    "    tag_data = {}\n",
    "    for page in pages_by_tag(tag, max_pages):\n",
    "        time.sleep(2)\n",
    "        page_data = parse_page(page, keys)\n",
    "        tag_data.update(page_data)\n",
    "    return tag_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = \"мастеркласс\"\n",
    "keys = [\n",
    "    \"text\",\n",
    "    \"taken_at_timestamp\",\n",
    "    \"edge_liked_by\",\n",
    "    \"owner\",\n",
    "    \"is_video\"\n",
    "]\n",
    "# stop_date = datetime.strptime(\"01.01.2019\", \"%d.%M.%Y\").timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_page_data(next(pages_by_tag(tag, 1)), keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_tag_data(\"мастеркласс\", keys, max_pages=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pd = pd.DataFrame.from_dict(data, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pd.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pd.to_csv(\"тэг_мастеркласс_300_страниц.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pd[\"taken_at_timestamp\"].map(lambda x: datetime.fromtimestamp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# html class for liked by\n",
    "liked_by_class = \"pbNvD fPMEg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://www.instagram.com/p/Bu1eDsZDMSx/liked_by/\")\n",
    "soup = BeautifulSoup(r.content, \"html.parser\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
